{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jbkoh/anaconda2/lib/python2.7/site-packages/matplotlib/__init__.py:1357: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    }
   ],
   "source": [
    "# Basic Modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.cluster.vq import *\n",
    "import operator\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "from matplotlib import pyplot as plt   \n",
    "import pickle as pkl\n",
    "import shelve\n",
    "import re\n",
    "from collections import Counter, defaultdict, OrderedDict\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import metrics#v_measure_score\n",
    "import scipy\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import csv\n",
    "import sys\n",
    "import math\n",
    "from copy import deepcopy\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import pickle\n",
    "import sys\n",
    "from multiprocessing import Pool\n",
    "import pp\n",
    "import shelve\n",
    "from collections import OrderedDict\n",
    "import json\n",
    "\n",
    "# ML modules\n",
    "#from sklearn.ensemble import AdaBoostClassifier\n",
    "#from sklearn import preprocessing\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.ensemble import BaggingClassifier\n",
    "#from sklearn.svm import OneClassSVM\n",
    "#from sklearn.mixture import GMM\n",
    "#from sklearn.mixture import DPGMM\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB\n",
    "#from sklearn.neural_network import BernoulliRBM as RBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('metadata/bacnet_devices.json','r') as fp:\n",
    "    sensor_dict = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "building_name = 'EBU3B'\n",
    "outputFilename = 'model/fe_' + building_name + '.pkl'\n",
    "\n",
    "with open('metadata/%s_sentence_dict.json'%building_name.lower(), 'r') as fp:\n",
    "    sentence_dict = json.load(fp)\n",
    "srcidList = sentence_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('metadata/building_info.json', 'r') as fp:\n",
    "    building_dict = json.load(fp)\n",
    "nae_list = building_dict[building_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import feature_extractor as fe\n",
    "def extract_features(srcidList, dummy):\n",
    "    resultList = list()\n",
    "    invalidSrcidList = list()\n",
    "    for srcid in srcidList:\n",
    "        #try:\n",
    "        filename = 'data/'+srcid+'.csv'\n",
    "        ts = pd.Series.from_csv(filename, header=0)\n",
    "        resultList.append((srcid, fe.get_features(ts)))\n",
    "        #except:\n",
    "        #    invalidSrcidList.append(srcid)\n",
    "        #    continue\n",
    "    #print invalidSrcidList\n",
    "    return resultList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "extract_features(srcidList,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ==============\n",
      "Starting pp with 4 workers\n",
      "An error has occured during the function execution\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jbkoh/anaconda2/lib/python2.7/site-packages/ppworker.py\", line 90, in run\n",
      "    __result = __f(*__args)\n",
      "  File \"<string>\", line 9, in extract_features\n",
      "NameError: global name 'pd' is not defined\n",
      "An error has occured during the function execution\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jbkoh/anaconda2/lib/python2.7/site-packages/ppworker.py\", line 90, in run\n",
      "    __result = __f(*__args)\n",
      "  File \"<string>\", line 9, in extract_features\n",
      "NameError: global name 'pd' is not defined\n",
      "An error has occured during the function execution\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jbkoh/anaconda2/lib/python2.7/site-packages/ppworker.py\", line 90, in run\n",
      "    __result = __f(*__args)\n",
      "  File \"<string>\", line 9, in extract_features\n",
      "NameError: global name 'pd' is not defined\n",
      "An error has occured during the function execution\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jbkoh/anaconda2/lib/python2.7/site-packages/ppworker.py\", line 90, in run\n",
      "    __result = __f(*__args)\n",
      "  File \"<string>\", line 9, in extract_features\n",
      "NameError: global name 'pd' is not defined\n",
      "Job execution statistics:\n",
      " job count | % of all jobs | job time sum | time per job | job server\n",
      "         4 |        100.00 |       4.8299 |     1.207485 | local\n",
      "Time elapsed since server creation 1.2414598465\n",
      "0 active tasks, 4 cores\n",
      "\n",
      "=-============\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate list (not \"NoneType\") to list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-f4eb275e0421>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresultList\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m#    print \"result: \", result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mdictList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdictList\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0mresultDict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdictList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mresultDict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate list (not \"NoneType\") to list"
     ]
    }
   ],
   "source": [
    "#p = Pool(4)\n",
    "#tempDict = dict((p.map(extract_features, srcidList)))\n",
    "\n",
    "ppservers = ()\n",
    "ncpus = 4\n",
    "rangeList = list()\n",
    "\n",
    "srcidList = ['505_0_3000043', '506_0_3000026', '505_0_3000003', '506_0_3000023',  '506_0_3000027']\n",
    "\n",
    "sensorsNum = len(srcidList)\n",
    "for i in range(0,ncpus):\n",
    "    rangeList.append(range(sensorsNum/ncpus*(i+1) - sensorsNum/ncpus, sensorsNum/ncpus*(i+1)))\n",
    "print \"==============\"\n",
    "\n",
    "jobServer = pp.Server(ncpus, ppservers=ppservers)\n",
    "print \"Starting pp with\", jobServer.get_ncpus(), \"workers\"\n",
    "jobList = list()\n",
    "for oneRange in rangeList:\n",
    "    #print [srcidList[i] for i in oneRange]\n",
    "    jobList.append(jobServer.submit(extract_features, ([srcidList[i] for i in oneRange], True)))\n",
    "\n",
    "resultList = list()\n",
    "resultList = [0,0,0,0]\n",
    "for i, job in enumerate(jobList):\n",
    "    resultList[i] = job()\n",
    "#r1 = jobList[0]()\n",
    "#r2 = jobList[1]()\n",
    "jobServer.wait()\n",
    "jobServer.print_stats()\n",
    "print \"=-============\"\n",
    "#print r1\n",
    "#print r2\n",
    "\n",
    "dictList = list()\n",
    "#print resultList\n",
    "for result in resultList:\n",
    "#    print \"result: \", result\n",
    "    dictList = dictList + result\n",
    "resultDict = dict(dictList)\n",
    "print resultDict\n",
    "\n",
    "#job_server = pp.Server(ncpus, ppservers=ppservers)\n",
    "#j1 = job_server.submit(extract_features, srcidList[0:1500])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
