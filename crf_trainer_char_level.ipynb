{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from functools import reduce\n",
    "import json                                                                     \n",
    "import random\n",
    "from collections import OrderedDict\n",
    "import pdb\n",
    "from copy import deepcopy\n",
    "from operator import itemgetter\n",
    "from itertools import islice\n",
    "\n",
    "from imp import reload\n",
    "\n",
    "import pycrfsuite                                                               \n",
    "import pandas as pd                                                             \n",
    "import numpy as np                    \n",
    "from IPython.display import Audio\n",
    "\n",
    "import resulter\n",
    "reload(resulter)\n",
    "from resulter import Resulter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "building_name = 'ebu3b'\n",
    "token_type = 'justseparate'\n",
    "label_type = 'label'\n",
    "\n",
    "data_available_buildings = []\n",
    "\n",
    "with open(\"metadata/%s_char_sentence_dict_%s.json\" \\\n",
    "          % (building_name, token_type), \"r\") as fp:\n",
    "    sentence_dict = json.load(fp)\n",
    "sentence_dict = dict((srcid, [char for char in sentence]) for (srcid, sentence) in sentence_dict.items())\n",
    "    \n",
    "with open('metadata/{0}_char_category_dict.json'.format(building_name), 'r') as fp:\n",
    "    char_category_dict = json.load(fp)\n",
    "with open('metadata/{0}_char_label_dict.json'.format(building_name), 'r') as fp:\n",
    "    char_label_dict = json.load(fp)\n",
    "    \n",
    "if label_type=='label':\n",
    "    label_dict = char_label_dict\n",
    "elif label_Type=='category':\n",
    "    label_dict = char_category_dict\n",
    "\n",
    "#sentence_dict = dict()\n",
    "#for srcid, sentence_label in label_dict.items():\n",
    "#    sentence_dict[srcid] = list(map(itemgetter(0), sentence_label))\n",
    "          \n",
    "    \n",
    "if building_name in data_available_buildings:\n",
    "    with open(\"model/fe_%s.json\"%building_name, \"r\") as fp:\n",
    "        data_feature_dict = json.load(fp)\n",
    "    with open(\"model/fe_%s.json\"%building_name, \"r\") as fp:\n",
    "        normalized_data_feature_dict = json.load(fp)\n",
    "    for srcid in sentence_dict.keys():\n",
    "        if not normalized_data_feature_dict.get(srcid):\n",
    "            normalized_data_feature_dict[srcid] = None\n",
    "\n",
    "cluster_filename = 'model/%s_word_clustering_%s.json' % (building_name, token_type)\n",
    "if os.path.isfile(cluster_filename):\n",
    "    with open(cluster_filename, 'r') as fp:\n",
    "        cluster_dict = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def calc_features(sentence,labels):\n",
    "def calc_features_deprecated(sentence, ts_features=None):\n",
    "    sentenceFeatures = list()\n",
    "    for i, word in enumerate(sentence):\n",
    "        features = [\n",
    "            'word.lower=' + word.lower(),\n",
    "            'word.isdigit=%s' % word.isdigit()\n",
    "        ]\n",
    "        if i>0:\n",
    "            features.extend([\n",
    "                    '-1:word.lower=' + sentence[i-1].lower()\n",
    "                ])\n",
    "        else:\n",
    "            features.append('BOS')\n",
    "            \n",
    "        if i<len(sentence)-1:\n",
    "            features.extend([\n",
    "                    '+1:word.lower=' + sentence[i+1].lower(),\n",
    "                ])\n",
    "        else:\n",
    "            features.append('EOS')\n",
    "        sentenceFeatures.append(features)\n",
    "    return sentenceFeatures\n",
    "\n",
    "#def calc_features(sentence,labels):\n",
    "def calc_features(sentence, ts_features=None):\n",
    "    sentenceFeatures = list()\n",
    "    sentence = ['$' if c.isdigit() else c for c in sentence]\n",
    "    for i, word in enumerate(sentence):\n",
    "        features = {\n",
    "            'word.lower='+word.lower(): 1.0,\n",
    "            'word.isdigit': float(word.isdigit())\n",
    "        }\n",
    "        if i==0:\n",
    "            features['BOS'] = 1.0\n",
    "        else:\n",
    "            features['-1:word.lower=' + sentence[i-1].lower()] = 1.0\n",
    "            \n",
    "        if i in [0,1]:\n",
    "            features['SECOND'] = 1.0\n",
    "        else:\n",
    "            features['-2:word.lower=' + sentence[i-2].lower()] = 1.0\n",
    "            \n",
    "        if i<len(sentence)-1:\n",
    "            features['+1:word.lower='+sentence[i+1].lower()] = 1.0\n",
    "        else:\n",
    "            features['EOS'] = 1.0\n",
    "        if ts_features:\n",
    "            for j, feat in enumerate(ts_features):\n",
    "                features['ts_feat_'+str(j)] = feat\n",
    "        sentenceFeatures.append(features)\n",
    "    return sentenceFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Learning Sample Selection\n",
    "USE_CLUSTER = True\n",
    "SAMPLE_NUM = 50\n",
    "\n",
    "sample_srcid_list = set()\n",
    "length_counter = lambda x:len(x[1])\n",
    "ander = lambda x,y:x and y\n",
    "labeled_srcid_list = list(label_dict.keys())\n",
    "if USE_CLUSTER:\n",
    "    sample_cnt = 0\n",
    "    sorted_cluster_dict = OrderedDict(sorted(cluster_dict.items(),key=length_counter, reverse=True))\n",
    "    while len(sample_srcid_list) < SAMPLE_NUM:\n",
    "        for cluster_num, srcid_list in sorted_cluster_dict.items():\n",
    "            valid_srcid_list = set(srcid_list).intersection(set(labeled_srcid_list))\\\n",
    "                                .difference(set(sample_srcid_list))\n",
    "            if len(valid_srcid_list) > 0:\n",
    "                sample_srcid_list.add(random.choice(list(valid_srcid_list)))\n",
    "            if len(sample_srcid_list) >= SAMPLE_NUM:\n",
    "                break\n",
    "else:\n",
    "    random_idx_list = random.sample(range(0,len(labeled_srcid_list)),SAMPLE_NUM)\n",
    "    sample_srcid_list = [labeled_srcid_list[i] for i in random_idx_list]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cluster counting (remove later)\n",
    "cluster_counter_dict = dict((cluster_id,0) for cluster_id in cluster_dict.keys())\n",
    "\n",
    "for srcid in sample_srcid_list:\n",
    "    for cluster_id, srcid_list in cluster_dict.items():\n",
    "        if srcid in srcid_list:\n",
    "            cluster_counter_dict[cluster_id] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "trainer = pycrfsuite.Trainer(verbose=False, algorithm='pa')#{‘lbfgs’, ‘l2sgd’, ‘ap’, ‘pa’, ‘arow’}\n",
    "trainer.set_params({'feature.possible_states': True,\n",
    "                    'feature.possible_transitions':True,                    \n",
    "                   })\n",
    "#for srcid, setence in sentence_dict.items():\n",
    "for srcid in sample_srcid_list:\n",
    "    sentence = list(map(itemgetter(0), label_dict[srcid]))\n",
    "    labels = list(map(itemgetter(1), label_dict[srcid]))\n",
    "    #trainer.append(pycrfsuite.ItemSequence(calc_features(sentence, labels)), labels)\n",
    "    if building_name in data_available_buildings:\n",
    "        data_features = normalized_data_feature_dict[srcid]\n",
    "    else:\n",
    "        data_features = None\n",
    "    trainer.append(pycrfsuite.ItemSequence(\n",
    "        calc_features(sentence, data_features)), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainer.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "crf_model_file = 'model/crf_params_char_{0}_{1}_{2}_{3}_{4}.crfsuite'\\\n",
    "                 .format(building_name, token_type, label_type, str(SAMPLE_NUM), 'clustered' if USE_CLUSTER else 'notclustered')\n",
    "trainer.train(crf_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tagger = pycrfsuite.Tagger()\n",
    "tagger.open(crf_model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "predicted_dict = dict()\n",
    "score_dict = dict()\n",
    "for srcid, sentence in sentence_dict.items():\n",
    "    if building_name in data_available_buildings:\n",
    "        data_features = normalized_data_feature_dict[srcid]\n",
    "    else:\n",
    "        data_features = None\n",
    "    predicted = tagger.tag(calc_features(sentence, data_features))\n",
    "    predicted_dict[srcid] = predicted\n",
    "    score_dict[srcid] = tagger.probability(predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "DEBUG = True\n",
    "precisionOfTrainingDataset = 0.0                                                \n",
    "totalWordCount = 0.0                                                            \n",
    "labeledSrcidList = list(label_dict.keys())\n",
    "randomSrcidList = sample_srcid_list\n",
    "resulter = Resulter()\n",
    "result_dict = dict()\n",
    "\n",
    "for srcid in sentence_dict.keys():\n",
    "    sentence = sentence_dict[srcid]                                              \n",
    "    predicted = predicted_dict[srcid]\n",
    "    if not srcid in list(label_dict.keys()):                                       \n",
    "        for word, predTag in zip(sentence, predicted): \n",
    "            if DEBUG:\n",
    "                pass\n",
    "                #print('{:20s} {:20s}'.format(word,predTag))\n",
    "            else:\n",
    "                pass\n",
    "    else:          \n",
    "        if srcid in randomSrcidList:\n",
    "            print(\"===================== %s TRAINING ==================== %e\" \n",
    "                  % (srcid, score_dict[srcid]))\n",
    "        else:\n",
    "            print(\"===================== %s TEST        ================= %e\" \n",
    "                  % (srcid, score_dict[srcid]))\n",
    "        printing_pairs = list()\n",
    "        sentence_label = label_dict[srcid]\n",
    "        label_list = list(map(itemgetter(1), sentence_label))\n",
    "        #sentence = list(map(itemgetter(0), sentence_label))\n",
    "        if srcid=='514_0_3006463':\n",
    "            #pdb.set_trace()\n",
    "            pass\n",
    "        resulter.add_one_result(srcid, sentence, predicted, label_list)\n",
    "        \n",
    "        for word, predTag, origLabel in zip(sentence, predicted, label_list):\n",
    "            printing_pair = [word,predTag,origLabel]\n",
    "            if origLabel=='soda':\n",
    "                pdb.set_trace()\n",
    "            if predTag==origLabel:                                          \n",
    "                precisionOfTrainingDataset += 1                             \n",
    "                printing_pair = ['O'] + printing_pair                       \n",
    "            else:                                                           \n",
    "                printing_pair = ['X'] + printing_pair                                       \n",
    "            totalWordCount += 1                                             \n",
    "            printing_pairs.append(printing_pair)                                \n",
    "        if 'X' in [pair[0] for pair in printing_pairs]:                         \n",
    "            for (flag, word, predTag, origLabel) in printing_pairs:\n",
    "                if DEBUG:\n",
    "                    print('{:5s} {:20s} {:20s} {:20s}'\\\n",
    "                          .format(flag, word, predTag, origLabel))                                          \n",
    "\n",
    "print(\"# Learning Sample: \",len(randomSrcidList))\n",
    "print(\"# Test Sample: \",len(label_dict) - len(randomSrcidList))\n",
    "print(\"Precision: \", precisionOfTrainingDataset/totalWordCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resulter.serialize_result('result/total.json')\n",
    "resulter.summarize_result()\n",
    "resulter.serialize_summary('result/summary.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Finished!!!\")\n",
    "sound_file = 'etc/fins_success.wav'\n",
    "Audio(url=sound_file, autoplay=True)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
