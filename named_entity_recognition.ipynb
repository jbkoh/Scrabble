{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pdb\n",
    "\n",
    "from brick_parser import tagsetList as tagset_list, \\\n",
    "                         tagList as tag_list,\\\n",
    "                         pointTagsetList as point_tagset_list\n",
    "#from imp import reload\n",
    "#reload(building_tokenizer)\n",
    "from building_tokenizer import get_unit_dict, get_bacnettype_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unit_dict = get_unit_dict(building_name)\n",
    "bacnettype_dict = get_bacnettype_dict(building_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def leave_one_word(s, w):\n",
    "    if w in s:\n",
    "        s = s.replace(w, '')\n",
    "        s = w + '-' + s\n",
    "    return s\n",
    "def _bilou_phraser(sentence, token_labels):                                     \n",
    "    phrase_labels = list()                                                  \n",
    "    curr_phrase = ''                                                        \n",
    "    for i, (c, label) in enumerate(zip(sentence, token_labels)):\n",
    "        if 'right_identifier' in label:\n",
    "            if 'right_identifier' not in curr_phrase and curr_phrase!='':\n",
    "                phrase_labels.append(curr_phrase)                           \n",
    "                curr_phrase = ''\n",
    "            curr_phrase += 'right_identifier'+c\n",
    "            continue\n",
    "        elif 'left_identifier' in label:\n",
    "            #pdb.set_trace()\n",
    "            if 'left_identifier' not in curr_phrase and curr_phrase!='':\n",
    "                phrase_labels.append(curr_phrase)\n",
    "                curr_phrase = ''\n",
    "            curr_phrase += 'left_identifier'+c\n",
    "            continue\n",
    "        tag = label[0]                                                      \n",
    "        if tag=='B':                                                        \n",
    "            if curr_phrase:                                                 \n",
    "            # Below is redundant if the other tags handles correctly.       \n",
    "                phrase_labels.append(curr_phrase)                           \n",
    "            curr_phrase = label[2:]                                         \n",
    "        elif tag=='I':                                                      \n",
    "            if curr_phrase != label[2:]:                                    \n",
    "                phrase_labels.append(curr_phrase)                           \n",
    "                curr_phrase = label[2:]                                     \n",
    "        elif tag=='L':                                                      \n",
    "            if curr_phrase != label[2:]:                                    \n",
    "                # Add if the previous label is different                    \n",
    "                phrase_labels.append(curr_phrase)                           \n",
    "            # Add current label                                             \n",
    "            phrase_labels.append(label[2:])                                 \n",
    "            curr_phrase = ''                                                \n",
    "        elif tag=='O':                                                      \n",
    "            # Do nothing other than pushing the previous label              \n",
    "            if curr_phrase:                                                 \n",
    "                phrase_labels.append(curr_phrase)                           \n",
    "            curr_phrase = ''                                                \n",
    "        elif tag=='U':                                                      \n",
    "            if curr_phrase:                                                 \n",
    "                phrase_labels.append(curr_phrase)                           \n",
    "            phrase_labels.append(label[2:])                                 \n",
    "        else:                                                               \n",
    "            print('Tag is incorrect in: {0}.'.format(label))                \n",
    "            try:                                                            \n",
    "                assert(False)                                               \n",
    "            except:                                                         \n",
    "                pdb.set_trace()\n",
    "    if curr_phrase!='':\n",
    "        phrase_labels.append(curr_phrase)\n",
    "    phrase_labels = [leave_one_word(leave_one_word(phrase_label, 'left_identifier'), 'right_identifier')\\\n",
    "                     for phrase_label in phrase_labels]\n",
    "    return phrase_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "source_building = 'ebu3b'\n",
    "target_building = 'ebu3b'\n",
    "\n",
    "N = 100\n",
    "token_type = 'justseparate'\n",
    "label_type = 'label'\n",
    "use_cluster_flag = True\n",
    "\n",
    "# This part should be changed to use MongoDB.\n",
    "label_filename = 'result/test_result_{0}_{1}_{2}_{3}_{4}_{5}.json'\\\n",
    "            .format(source_building, target_building, token_type, label_type, N,\\\n",
    "                    'clustered' if use_cluster_flag else 'unclustered')\n",
    "with open(label_filename, 'r') as fp:\n",
    "    word_label_dict = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = word_label_dict['506_2_3015076']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['network_adapter-nae',\n",
       " 'left_identifier-06',\n",
       " 'average',\n",
       " 'floor',\n",
       " 'cooling',\n",
       " 'demand',\n",
       " 'right_identifier-3rd',\n",
       " 'floor',\n",
       " 'average',\n",
       " 'cooling',\n",
       " 'right_identifier-3rd',\n",
       " 'floor',\n",
       " 'average',\n",
       " 'cooling',\n",
       " 'left_identifier-2',\n",
       " 'building-ebu3b',\n",
       " 'left_identifier-3b',\n",
       " 'room',\n",
       " 'left_identifier-3',\n",
       " 'right_identifier-3rd',\n",
       " 'floor',\n",
       " 'average',\n",
       " 'cooling',\n",
       " 'left_identifier-2',\n",
       " 'average',\n",
       " 'floor',\n",
       " 'cooling',\n",
       " 'left_identifier-2']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_bilou_phraser(a['sentence'], a['orig_token_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'nae 06 programming average floor cooling demand 3rd flr avg clg 3rd flr avg clg pid2\\nebu3b.rm-3xxx..3rd flr avg clg-pid2\\naverage floor cooling pid2\\n'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(a['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1461"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(point_tagset_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def splitter(s):\n",
    "    return s.split('_')\n",
    "point_tagset_list = list(map(splitter, point_tagset_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['temperature', 'alarm']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point_tagset_list[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
