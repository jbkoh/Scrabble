{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pdb\n",
    "from collections import OrderedDict\n",
    "import random\n",
    "import pdb\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.sparse import vstack\n",
    "\n",
    "from brick_parser import tagsetList as tagset_list, \\\n",
    "                         tagList as tag_list,\\\n",
    "                         pointTagsetList as point_tagset_list\n",
    "#from imp import reload\n",
    "#reload(building_tokenizer)\n",
    "from building_tokenizer import get_unit_dict, get_bacnettype_dict\n",
    "tagset_list = list(set(tagset_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Note:\n",
    "# May need to remove \"unknown\" data points from learning samples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "building_name = 'ebu3b'\n",
    "learning_sample_num = 50\n",
    "unit_dict = get_unit_dict(building_name)\n",
    "bacnettype_dict = get_bacnettype_dict(building_name)\n",
    "with open('metadata/{0}_ground_truth.json'.format(building_name), 'r') as fp:\n",
    "    truth_dict = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def leave_one_word(s, w):\n",
    "    if w in s:\n",
    "        s = s.replace(w, '')\n",
    "        s = w + '-' + s\n",
    "    return s\n",
    "def _bilou_phraser(sentence, token_labels):                                     \n",
    "    phrase_labels = list()                                                  \n",
    "    curr_phrase = ''                                                        \n",
    "    for i, (c, label) in enumerate(zip(sentence, token_labels)):\n",
    "        \"\"\"\n",
    "        if 'right_identifier' in label:\n",
    "            if 'right_identifier' not in curr_phrase and curr_phrase!='':\n",
    "                phrase_labels.append(curr_phrase)                           \n",
    "                curr_phrase = ''\n",
    "            curr_phrase += 'right_identifier'+c\n",
    "            continue\n",
    "        elif 'left_identifier' in label:\n",
    "            #pdb.set_trace()\n",
    "            if 'left_identifier' not in curr_phrase and curr_phrase!='':\n",
    "                phrase_labels.append(curr_phrase)\n",
    "                curr_phrase = ''\n",
    "            curr_phrase += 'left_identifier'+c\n",
    "            continue\n",
    "        \"\"\"\n",
    "        if label[2:] in ['right_identifier', 'left_identifier']:\n",
    "            continue\n",
    "        tag = label[0]                                                      \n",
    "        if tag=='B':                                                        \n",
    "            if curr_phrase:                                                 \n",
    "            # Below is redundant if the other tags handles correctly.       \n",
    "                phrase_labels.append(curr_phrase)                           \n",
    "            curr_phrase = label[2:]                                         \n",
    "        elif tag=='I':                                                      \n",
    "            if curr_phrase != label[2:]:                                    \n",
    "                phrase_labels.append(curr_phrase)                           \n",
    "                curr_phrase = label[2:]                                     \n",
    "        elif tag=='L':                                                      \n",
    "            if curr_phrase != label[2:]:                                    \n",
    "                # Add if the previous label is different                    \n",
    "                phrase_labels.append(curr_phrase)                           \n",
    "            # Add current label                                             \n",
    "            phrase_labels.append(label[2:])                                 \n",
    "            curr_phrase = ''                                                \n",
    "        elif tag=='O':                                                      \n",
    "            # Do nothing other than pushing the previous label              \n",
    "            if curr_phrase:                                                 \n",
    "                phrase_labels.append(curr_phrase)                           \n",
    "            curr_phrase = ''                                                \n",
    "        elif tag=='U':                                                      \n",
    "            if curr_phrase:                                                 \n",
    "                phrase_labels.append(curr_phrase)                           \n",
    "            phrase_labels.append(label[2:])                                 \n",
    "        else:                                                               \n",
    "            print('Tag is incorrect in: {0}.'.format(label))                \n",
    "            try:                                                            \n",
    "                assert(False)                                               \n",
    "            except:                                                         \n",
    "                pdb.set_trace()\n",
    "    if curr_phrase!='':\n",
    "        phrase_labels.append(curr_phrase)\n",
    "    phrase_labels = [leave_one_word(leave_one_word(phrase_label, 'left_identifier'), 'right_identifier')\\\n",
    "                     for phrase_label in phrase_labels]\n",
    "    return phrase_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "source_building = 'ebu3b'\n",
    "target_building = 'ebu3b'\n",
    "\n",
    "N = 100\n",
    "token_type = 'justseparate'\n",
    "label_type = 'label'\n",
    "use_cluster_flag = True\n",
    "\n",
    "# This part should be changed to use MongoDB.\n",
    "label_filename = 'result/test_result_{0}_{1}_{2}_{3}_{4}_{5}.json'\\\n",
    "            .format(source_building, target_building, token_type, label_type, N,\\\n",
    "                    'clustered' if use_cluster_flag else 'unclustered')\n",
    "with open(label_filename, 'r') as fp:\n",
    "    word_label_dict = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "orig_phrase_dict = OrderedDict()\n",
    "pred_phrase_dict = OrderedDict()\n",
    "for srcid, labels in word_label_dict.items():\n",
    "    orig_phrase_dict[srcid] = _bilou_phraser(labels['sentence'], labels['orig_token_labels'])\n",
    "    pred_phrase_dict[srcid] = _bilou_phraser(labels['sentence'], labels['pred_token_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def splitter(s):\n",
    "    return s.split('_')\n",
    "point_tagset_list = list(map(splitter, point_tagset_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "doc = [' '.join(phrases) for phrases in orig_phrase_dict.values()]\n",
    "vect_doc = vectorizer.fit_transform(doc)\n",
    "srcid_list = list(orig_phrase_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(srcid_list)==len(vect_doc.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_srcids = random.sample(srcid_list, learning_sample_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find undefined tagsets (names)\n",
    "undefined_tagsets = set()\n",
    "for srcid in sample_srcids:\n",
    "    truths = truth_dict[srcid]\n",
    "    for truth in truths:\n",
    "        if truth not in tagset_list:\n",
    "            undefined_tagsets.add(truth)\n",
    "tagset_list.extend(list(undefined_tagsets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "truth_mat = list()\n",
    "feature_mat = list()\n",
    "for srcid in sample_srcids:\n",
    "    truths = truth_dict[srcid]\n",
    "    truth_vector = [1 if tagset in truths else 0 for tagset in tagset_list]\n",
    "    truth_mat.append(truth_vector)\n",
    "    feature_mat.append(vect_doc[srcid_list.index(srcid)])\n",
    "feature_mat = vstack(feature_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner = RandomForestClassifier()\n",
    "learner.fit(feature_mat, truth_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "srcid = random.sample(srcid_list, 1)[0]\n",
    "assert(srcid not in sample_srcids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_features = vect_doc[srcid_list.index(srcid)]\n",
    "pred = learner.predict(sample_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vav',\n",
       " 'effective_heating_temperature_setpoint',\n",
       " 'room',\n",
       " 'network_adapter-nae',\n",
       " 'building-ebu3b',\n",
       " 'network_adapter-n']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = [i for i, v in enumerate(pred[0]) if v==1]\n",
    "[tagset_list[idx] for idx in indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['effective_heating_temperature_setpoint',\n",
       " 'room',\n",
       " 'building-ebu3b',\n",
       " 'network_adapter-nae',\n",
       " 'network_adapter-n',\n",
       " 'vav']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "truth_dict[srcid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
