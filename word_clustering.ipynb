{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#essential libraries\n",
    "import json\n",
    "import operator\n",
    "import shelve\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt   \n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.cluster.vq import *\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import scipy\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "import scipy.cluster.hierarchy as hier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "building_name = 'ghc'\n",
    "token_type = 'justseparate'\n",
    "with open('metadata/%s_sentence_dict_%s.json' % (building_name, token_type), 'r') as fp:\n",
    "    sentence_dict = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "adder = lambda x,y:x+y\n",
    "sentence_list = list()\n",
    "srcid_list = list()\n",
    "for srcid, sentence in sentence_dict.items():\n",
    "    srcid_list.append(srcid)\n",
    "    sentence_list.append(' '.join([word for word in sentence if re.match('[a-zA-Z]+', word)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function scipy.sparse.construct.hstack>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer()\n",
    "bow = scipy.sparse.coo_matrix(vect.fit_transform(sentence_list))\n",
    "bow_array = bow.toarray()\n",
    "feature_set = vect.get_feature_names()\n",
    "scipy.sparse.hstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_of_sensors = len(bow_array)\n",
    "a = np.array(bow_array[:num_of_sensors])\n",
    "z = linkage(a, metric='cityblock', method='complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold:  3.5\n"
     ]
    }
   ],
   "source": [
    "#Apply threshold to hierarchical tree to obtain individual clusters. Results stored in equip_map\n",
    "dists = list(set(z[:,2]))\n",
    "thresh = (dists[3] + dists[4]) /2 \n",
    "print(\"Threshold: \", thresh)\n",
    "b = hier.fcluster(z,thresh, criterion='distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "761\n"
     ]
    }
   ],
   "source": [
    "cluster_dict = defaultdict(list)\n",
    "\n",
    "for srcid, cluster_id in zip(srcid_list, b):\n",
    "    cluster_dict[str(cluster_id)].append(srcid)\n",
    "cluster_dict = dict(cluster_dict)\n",
    "\n",
    "with open('model/%s_word_clustering_%s.json' % (building_name, token_type.lower()), 'w') as fp:\n",
    "    json.dump(cluster_dict, fp, indent=4, sort_keys=True)\n",
    "print(len(cluster_dict))    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
