{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jbkoh/anaconda2/lib/python2.7/site-packages/matplotlib/__init__.py:1350: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n",
      "INFO:rdflib:RDFLib Version: 4.2.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Graph\n",
      "Load Brick.ttl\n",
      "Load BrickFrame.ttl\n",
      "Init Graph\n",
      "Load Brick.ttl\n",
      "Load BrickFrame.ttl\n"
     ]
    }
   ],
   "source": [
    "#essential libraries\n",
    "\n",
    "#from google_drive import gdrive\n",
    "\n",
    "from matplotlib.pyplot import show\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.cluster.vq import *\n",
    "import operator\n",
    "import matplotlib\n",
    "reload(matplotlib)\n",
    "#matplotlib.use('Agg')\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "import shelve\n",
    "import re\n",
    "from collections import Counter, defaultdict, OrderedDict, deque\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import metrics\n",
    "import scipy\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import csv\n",
    "import sys\n",
    "import math\n",
    "from copy import deepcopy, copy\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from operator import itemgetter\n",
    "from itertools import chain\n",
    "import os\n",
    "import gc\n",
    "import linecache\n",
    "import multiprocessing\n",
    "from functools import partial\n",
    "from itertools import repeat\n",
    "from IPython.display import clear_output\n",
    "import json\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter()\n",
    "\n",
    "import rdflib\n",
    "from rdflib.namespace import OWL, RDF, RDFS\n",
    "from rdflib import URIRef\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import OneClassSVM, SVC\n",
    "from sklearn.mixture import GMM\n",
    "from sklearn.mixture import DPGMM\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "import scipy.cluster.hierarchy as hier\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "from scipy import spatial\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn import metrics\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "import scipy.cluster.hierarchy as hier\n",
    "from scipy import stats\n",
    "from numpy.testing import assert_almost_equal\n",
    "\n",
    "from scipy.spatial.distance import cosine as cosine_similarity\n",
    "\n",
    "from divergence import gau_js as js_divergence\n",
    "import brick_parser\n",
    "reload(brick_parser)\n",
    "from brick_parser import tagList, tagsetList, equipTagsetList, pointTagsetList, locationTagsetList,\\\n",
    "equalDict, pointTagList, equipTagList, locationTagList, equipPointDict\n",
    "subTagListDict = dict([('point', pointTagList),\n",
    "                          ('equip', equipTagList),\n",
    "                          ('location', locationTagList)\n",
    "                         ])\n",
    "subTagsetListDict = dict([('point', pointTagsetList),\n",
    "                          ('equip', equipTagsetList),\n",
    "                          ('location', locationTagsetList)\n",
    "                         ])\n",
    "\n",
    "#from cmu_parser import cmu_building_parse\n",
    "\n",
    "debugFlag = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import building_tokenizer\n",
    "reload(building_tokenizer)\n",
    "import building_tokenizer as toker\n",
    "\n",
    "buildingName = 'ebu3b'\n",
    "notUcsdBuildings = ['ghc']\n",
    "\n",
    "tokenType = 'NoNumber'\n",
    "if not buildingName in notUcsdBuildings:\n",
    "    naeDict = dict()\n",
    "    naeDict['bonner'] = [\"607\", \"608\", \"609\", \"557\", \"610\"]\n",
    "    naeDict['ap_m'] = ['514', '513','604']\n",
    "    naeDict['bsb'] = ['519', '568', '567', '566', '564', '565']\n",
    "    naeDict['ebu3b'] = [\"505\", \"506\"]\n",
    "    #naeDict['otterson'] = [\"518\", \"517\", \"589\", \"590\"]\n",
    "    naeList = naeDict[buildingName]\n",
    "\n",
    "    labeledFile = 'metadata/' + buildingName + '_sensor_types_location.csv'\n",
    "    with open(labeledFile, 'rb') as fp:\n",
    "        #truthDF = pd.read_excel(fp)\n",
    "        truthDF = pd.DataFrame.from_csv(fp)\n",
    "        #truthDF = truthDF.set_index(keys='Unique Identifier')\n",
    "\n",
    "    wordFeatFile = 'data/wordfeat_'+buildingName+'.pkl'\n",
    "\n",
    "    tokenTypeList = ['NoNumber', 'Alphanumeric', 'AlphaAndNum', 'NumAsSingleWord']\n",
    "\n",
    "    bacnetTypeMapDF = pd.DataFrame.from_csv('metadata/bacnettype_mapping.csv')\n",
    "    unitMap = pd.read_csv('metadata/unit_mapping.csv').set_index('unit')\n",
    "    for val in Counter(unitMap.keys()).values():\n",
    "        if val>1:\n",
    "            \"Unit map file ERROR\"\n",
    "            assert(False)\n",
    "            \n",
    "            \n",
    "    trueDF = pd.DataFrame.from_csv('metadata/'+buildingName+'_sensor_types_location.csv')\n",
    "    sensorDF, nameList, jcinameList, descList, unitList, bacnettypeList, wordList = \\\n",
    "    toker.structure_metadata(buildingName=buildingName, tokenType=tokenType, \\\n",
    "                             validSrcidList=trueDF.index.tolist(), withDotFlag=False)\n",
    "\n",
    "    origSensorDF = deepcopy(sensorDF)\n",
    "    origNameList = deepcopy(nameList)\n",
    "    origJcinameList = deepcopy(jcinameList)\n",
    "    origDescList = deepcopy(descList)\n",
    "    origUnitList = deepcopy(unitList)\n",
    "    origBacnettypeList = deepcopy(bacnettypeList)\n",
    "    origWordList = deepcopy(wordList)\n",
    "\n",
    "    #_, rawNameList, rawJcinameList, rawDescList, _, _, _ = toker.structure_metadata(buildingName=buildingName, tokenType='AlphaAndNum', \\\n",
    "    _, rawNameList, rawJcinameList, rawDescList, _, _, _ =\\\n",
    "    toker.structure_metadata(buildingName=buildingName, tokenType='JustSeparate', \\\n",
    "                             validSrcidList=trueDF.index.tolist(), withDotFlag=False)\n",
    "    \n",
    "    \n",
    "else: \n",
    "    filename = 'metadata/'+buildingName+'_sensor_types_location.csv'\n",
    "    #   filename = 'metadata/%s_sensor_types_location.csv'%buildingName\n",
    "    df = pd.read_csv(filename)\n",
    "    sentenceDict = dict()    \n",
    "    for i,raw in enumerate(df['bas_raw'].tolist()):\n",
    "        sentenceDict[i] = toker.tokenize(tokenType, raw)\n",
    "    \n",
    "    \n",
    "## Common part\n",
    "    \n",
    "#with open('data/'+buildingName+'_str_score_dict.pkl', 'rb') as fp:\n",
    "#    scoreDictDict = pickle.load(fp)\n",
    "#    ### If a word is exactly matched with another, fix it.\n",
    "#    for word, scoreDict in scoreDictDict.items():\n",
    "#        if word in scoreDict.keys():\n",
    "#            scoreDictDict[word] = {word:1}\n",
    "#    scoreDictDict['co'] = {'co2':1}\n",
    "        \n",
    "adder = lambda x,y:x+y\n",
    "splitter = lambda x:x.split()\n",
    "bacnetTypes = list(set(reduce(adder,map(splitter,origBacnettypeList),[])))\n",
    "#for bacnetType in bacnetTypes:\n",
    "#    scoreDictDict[bacnetType] = {bacnetType:1}\n",
    "#units = list(set(unitMap['word'].tolist()))\n",
    "#for unit in units:\n",
    "#    if type(unit)==str:\n",
    "#        scoreDictDict[unit] = {unit:1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"metadata/%s_sentence_dict.json\"%buildingName, \"r\") as fp:\n",
    "    sentenceDict = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "known_label_dict = {\n",
    "    'nae':'none',\n",
    "    'n': 'none',\n",
    "    'ebu': 'building',\n",
    "    'b': 'identifier', # b could be basement, which is ignored currently.\n",
    "    'rm':'room',\n",
    "    'vma':'vav',\n",
    "    'newline':'none',\n",
    "    'vnd':'vnd',\n",
    "    'cmd':'command',\n",
    "    'zn':'zone',\n",
    "    'chilled_water_pump': 'chwp',\n",
    "    'clgpid':'cooling_command',\n",
    "    'htgpid':'heating_command',\n",
    "    'rh':'reheat',\n",
    "    'vlv':'valve',\n",
    "    'supflo':'supply_air_flow',\n",
    "    'sup':'supply',\n",
    "    'rf':'return_fan',\n",
    "    'clgmaxflo':'cooling_max_supply_air_flow_setpoint',\n",
    "    'dx':'network_adapter',\n",
    "    'hwp':'hot_water_pump',\n",
    "    'sys':'system',\n",
    "    'dpr':'damper',\n",
    "    'chwp':'chilled_water_pump',\n",
    "    'stpt':'setpoint',\n",
    "    'clgminflo':'cooling_min_supply_air_flow_setpoint',\n",
    "    'clg':'cooling',\n",
    "    'dx':'network_adapter',\n",
    "    'dmpr':'damper',\n",
    "    'pos':'position',\n",
    "    'actclgsp':'effective_cooling_temperature_setpoint',\n",
    "    'clgminflo':'cooling_min_supply_air_flow_setpoint',\n",
    "    'dpr':'damper',\n",
    "    'clgmaxflo':'cooling_max_supply_air_flow_setpoint',\n",
    "    'adj':'adjust',\n",
    "    'commonsp':'temperature_setpoint',\n",
    "    'htgflo':'heating_supply_air_flow_setpoint',\n",
    "    'htg':'heating',\n",
    "    'acthtgsp':'effective_heating_temperature_setpoint',\n",
    "    'sen':'sensor',\n",
    "    'supflosp':'supply_air_flow_setpoint',\n",
    "    'dmprpos':'damper_position',\n",
    "    'htgflow':'heating_supply_air_flow_setpoint',\n",
    "    'sf':'supply_fan',\n",
    "    'chilled_water',\n",
    "    'alm':'alarm',\n",
    "    \n",
    "}\n",
    "known_word_list = known_label_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ask_expert_labels(sentence):\n",
    "    # Input: List of words\n",
    "    # Output: feature list:\n",
    "    # Human operation: Give labels on the words.\n",
    "    sliceSize = 2\n",
    "    featureDict = dict()\n",
    "    \n",
    "    nonBrickTagList = ['none', 'identifier', 'network_adapter', 'vnd', 'unknown']\n",
    "\n",
    "    #for words in rolling_window(sentence, 2):\n",
    "    #    for word in wo\n",
    "    print(\"\\nGiven sentence: %s\"%sentence)\n",
    "    labelList = list()\n",
    "    for word in sentence:\n",
    "        if re.match('[^0-9a-zA-Z]+', word):\n",
    "            labelList.append('none')\n",
    "            continue\n",
    "        if re.match('\\d+', word):\n",
    "            labelList.append('identifier')\n",
    "            continue\n",
    "        if word in known_word_list:\n",
    "            labelList.append(known_label_dict[word])\n",
    "            continue\n",
    "        if word in tagList:\n",
    "            labelList.append(word)\n",
    "            continue\n",
    "            \n",
    "            \n",
    "        while True:\n",
    "            label = raw_input(str(word)+': \\n')\n",
    "            if label in tagList or label in tagsetList or label in nonBrickTagList:\n",
    "                labelList.append(label)\n",
    "                break\n",
    "            else:\n",
    "                print(\"Pick Tag among the following tags: \" + str(tagList))\n",
    "    return labelList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "splitter = lambda x:x.split(' ')\n",
    "train_sents = list()\n",
    "for row in zip(rawNameList, rawJcinameList, rawDescList):\n",
    "    para = list()\n",
    "    for ele in row:\n",
    "        para.extend([x for x in ele.split(' ') if x!=''])\n",
    "        para.append('\\n')\n",
    "    train_sents.append(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-38-f1b453c5c056>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-38-f1b453c5c056>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    for srcid, labelLi\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Review labelListDict\n",
    "reviewedLabelListDict = dict()\n",
    "\n",
    "for srcid, labelLi\n",
    "st in labelListDict.items():\n",
    "    reviewedLabelList = list()\n",
    "    for word, label in zip(sentenceDict[srcid], labelList):\n",
    "        x = raw_input(word + \"\\t\" + label)\n",
    "        if x=='':\n",
    "            reviewedLabelList.append(label)\n",
    "        else:\n",
    "            reviewedLabelList.append(x)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labelFilename = 'metadata/%s_label_dict.json'%buildingName\n",
    "with open(labelFilename, 'r') as fp:\n",
    "    labelListDict = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Given sentence: [u'nae', u'05', u'n', u'2', u'1', u'vma', u'106', u'dmpr', u'pos', u'newline', u'ebu', u'3', u'b', u'.', u'rm', u'-', u'b', u'250', u'a', u'.', u'.', u'dmpr', u'-', u'pos', u'newline', u'damper', u'position', u'newline']\n",
      "a: \n",
      "identifier\n",
      "\n",
      "Given sentence: [u'nae', u'06', u'n', u'2', u'1', u'vma', u'105', u'occ', u'cmd', u'newline', u'ebu', u'3', u'b', u'.', u'rm', u'-', u'2240', u'.', u'.', u'occ', u'-', u'cmd', u'newline', u'occupied', u'command', u'newline']\n",
      "occ: \n",
      "occupied\n",
      "occ: \n",
      "occupied\n",
      "\n",
      "Given sentence: [u'nae', u'05', u'n', u'2', u'1', u'vma', u'103', u'htgflow', u'newline', u'ebu', u'3', u'b', u'.', u'rm', u'-', u'b', u'225', u'.', u'.', u'htgflow', u'newline', u'occupied', u'htg', u'flow', u'newline']\n",
      "\n",
      "Given sentence: [u'nae', u'06', u'n', u'2', u'1', u'vma', u'158', u'htgflow', u'newline', u'ebu', u'3', u'b', u'.', u'rm', u'-', u'3200', u'a', u'.', u'.', u'htgflow', u'newline', u'occupied', u'htg', u'flow', u'newline']\n",
      "a: \n",
      "identifier\n",
      "\n",
      "Given sentence: [u'nae', u'05', u'n', u'2', u'2', u'vma', u'107', u'clgpid', u'o', u'newline', u'ebu', u'3', u'b', u'.', u'rm', u'-', u'1207', u'.', u'.', u'clgpid', u'-', u'o', u'newline', u'cooling', u'command', u'newline']\n",
      "o: \n",
      "none\n",
      "o: \n",
      "none\n",
      "\n",
      "Given sentence: [u'nae', u'05', u'n', u'2', u'2', u'vma', u'113', u'clgminflo', u'newline', u'ebu', u'3', u'b', u'.', u'rm', u'-', u'1231', u'.', u'.', u'clgminflo', u'newline', u'occupied', u'clg', u'min', u'newline']\n",
      "\n",
      "Given sentence: [u'nae', u'06', u'n', u'2', u'2', u'vma', u'179', u'zn', u't', u'newline', u'ebu', u'3', u'b', u'.', u'rm', u'-', u'4144', u'.', u'.', u'zn', u'-', u't', u'newline', u'zone', u'temperature', u'newline']\n",
      "t: \n",
      "temperature\n",
      "t: \n",
      "temperature\n",
      "\n",
      "Given sentence: [u'nae', u'05', u'n', u'2', u'1', u'vma', u'111', u'dmpr', u'pos', u'newline', u'ebu', u'3', u'b', u'.', u'rm', u'-', u'b', u'200', u'b', u'.', u'.', u'dmpr', u'-', u'pos', u'newline', u'damper', u'position', u'newline']\n",
      "\n",
      "Given sentence: [u'nae', u'06', u'n', u'2', u'1', u'vma', u'116', u'w', u'c', u'adj', u'newline', u'ebu', u'3', u'b', u'.', u'rm', u'-', u'2236', u'.', u'.', u'w', u'-', u'c', u'-', u'adj', u'newline', u'warm', u'/', u'cool', u'adjust', u'newline']\n",
      "w: \n",
      "warm\n",
      "c: \n",
      "cool\n",
      "w: \n",
      "warm\n",
      "c: \n",
      "cool\n",
      "\n",
      "Given sentence: [u'nae', u'06', u'n', u'2', u'2', u'vma', u'132', u'clgpid', u'o', u'newline', u'ebu', u'3', u'b', u'.', u'rm', u'-', u'4154', u'.', u'.', u'clgpid', u'-', u'o', u'newline', u'cooling', u'command', u'newline']\n",
      "o: \n",
      "none\n",
      "o: \n",
      "none\n",
      "\n",
      "Given sentence: [u'nae', u'06', u'n', u'2', u'1', u'vma', u'177', u'dpr', u'c', u'newline', u'ebu', u'3', u'b', u'.', u'rm', u'-', u'3256', u'.', u'.', u'dpr', u'-', u'c', u'newline', u'damper', u'command', u'newline']\n",
      "c: \n",
      "command\n",
      "c: \n",
      "command\n",
      "\n",
      "Given sentence: [u'nae', u'06', u'n', u'2', u'2', u'vma', u'108', u'htgflow', u'newline', u'ebu', u'3', u'b', u'.', u'rm', u'-', u'3130', u'.', u'.', u'htgflow', u'newline', u'occupied', u'htg', u'flow', u'newline']\n",
      "\n",
      "Given sentence: [u'nae', u'05', u'n', u'2', u'2', u'vma', u'119', u'clgminflo', u'newline', u'ebu', u'3', u'b', u'.', u'rm', u'-', u'1212', u'.', u'.', u'clgminflo', u'newline', u'occupied', u'clg', u'min', u'newline']\n",
      "\n",
      "Given sentence: [u'nae', u'05', u'n', u'2', u'2', u'vma', u'137', u'supflo', u'sp', u'newline', u'ebu', u'3', u'b', u'.', u'rm', u'-', u'1151', u'.', u'.', u'supflo', u'-', u'sp', u'newline', u'actual', u'sup', u'flow', u'sp', u'newline']\n",
      "sp: \n",
      "setpoint\n",
      "sp: \n",
      "setpoint\n",
      "actual: \n",
      "none\n",
      "sp: \n",
      "setpoint\n",
      "\n",
      "Given sentence: [u'nae', u'06', u'n', u'2', u'2', u'vma', u'118', u'htgpid', u'o', u'newline', u'ebu', u'3', u'b', u'.', u'rm', u'-', u'3107', u'.', u'.', u'htgpid', u'-', u'o', u'newline', u'heating', u'command', u'newline']\n",
      "o: \n",
      "none\n",
      "o: \n",
      "none\n",
      "\n",
      "Given sentence: [u'nae', u'06', u'n', u'2', u'1', u'vma', u'105', u'htgflow', u'newline', u'ebu', u'3', u'b', u'.', u'rm', u'-', u'2240', u'.', u'.', u'htgflow', u'newline', u'occupied', u'htg', u'flow', u'newline']\n",
      "\n",
      "Given sentence: [u'nae', u'05', u'n', u'2', u'1', u'dx', u'12', u'file', u'server', u'chw', u'system', u'chwp', u'4', u'alm', u'newline', u'ebu', u'3', u'b', u'.', u'fschw', u'.', u'chwp', u'4', u'-', u'alm', u'newline', u'chilled', u'water', u'pump', u'4', u'alarm', u'newline']\n",
      "file: \n",
      "none\n",
      "chw: \n",
      "chilled_water\n",
      "alm: \n",
      "alarm\n",
      "fschw: \n",
      "chilled_water\n",
      "alm: \n",
      "alarm\n",
      "\n",
      "Given sentence: [u'nae', u'06', u'n', u'2', u'1', u'vma', u'133', u'htgpid', u'o', u'newline', u'ebu', u'3', u'b', u'.', u'rm', u'-', u'2136', u'.', u'.', u'htgpid', u'-', u'o', u'newline', u'heating', u'command', u'newline']\n",
      "o: \n",
      "none\n",
      "o: \n",
      "none\n",
      "\n",
      "Given sentence: [u'nae', u'06', u'n', u'2', u'1', u'vma', u'149', u'clgpid', u'o', u'newline', u'ebu', u'3', u'b', u'.', u'rm', u'-', u'2150', u'.', u'.', u'clgpid', u'-', u'o', u'newline', u'cooling', u'command', u'newline']\n",
      "o: \n",
      "none\n",
      "o: \n",
      "none\n"
     ]
    }
   ],
   "source": [
    "labelSampleNum = 20\n",
    "for i in random.sample(range(0,len(sensorDF)), labelSampleNum):\n",
    "    srcid = sensorDF.iloc[i].name\n",
    "    if not srcid in labelListDict.keys():\n",
    "        labelListDict[srcid] = ask_expert_labels(sentenceDict[srcid])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182\n"
     ]
    }
   ],
   "source": [
    "print len(labelListDict)\n",
    "with open(labelFilename, 'w') as fp:\n",
    "    json.dump(labelListDict,fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "#with open(labelFilename, 'w') as fp:\n",
    "#    json.dump(labelListDict,fp)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
