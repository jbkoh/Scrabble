{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Graph\n",
      "Load Brick.ttl\n",
      "Load BrickFrame.ttl\n"
     ]
    }
   ],
   "source": [
    "#essential libraries\n",
    "\n",
    "#from google_drive import gdrive\n",
    "\n",
    "from matplotlib.pyplot import show\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.cluster.vq import *\n",
    "import operator\n",
    "#import matplotlib\n",
    "#matplotlib.use('Agg')\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "import shelve\n",
    "import re\n",
    "from collections import Counter, defaultdict, OrderedDict, deque\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import metrics\n",
    "import scipy\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import csv\n",
    "import sys\n",
    "import math\n",
    "from copy import deepcopy, copy\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from operator import itemgetter\n",
    "from itertools import chain\n",
    "import os\n",
    "import gc\n",
    "import linecache\n",
    "import multiprocessing\n",
    "from functools import partial\n",
    "from itertools import repeat\n",
    "from IPython.display import clear_output\n",
    "import json\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter()\n",
    "\n",
    "import rdflib\n",
    "from rdflib.namespace import OWL, RDF, RDFS\n",
    "from rdflib import URIRef\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import OneClassSVM, SVC\n",
    "from sklearn.mixture import GMM\n",
    "from sklearn.mixture import DPGMM\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB, GaussianNB\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "import scipy.cluster.hierarchy as hier\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "from scipy import spatial\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn import metrics\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "import scipy.cluster.hierarchy as hier\n",
    "from scipy import stats\n",
    "from numpy.testing import assert_almost_equal\n",
    "\n",
    "from scipy.spatial.distance import cosine as cosine_similarity\n",
    "\n",
    "from divergence import gau_js as js_divergence\n",
    "from brick_parser import tagList, tagsetList, equipTagsetList, pointTagsetList, locationTagsetList,\\\n",
    "equalDict, pointTagList, equipTagList, locationTagList, equipPointDict\n",
    "subTagListDict = dict([('point', pointTagList),\n",
    "                          ('equip', equipTagList),\n",
    "                          ('location', locationTagList)\n",
    "                         ])\n",
    "subTagsetListDict = dict([('point', pointTagsetList),\n",
    "                          ('equip', equipTagsetList),\n",
    "                          ('location', locationTagsetList)\n",
    "                         ])\n",
    "\n",
    "#from cmu_parser import cmu_building_parse\n",
    "\n",
    "debugFlag = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import imp\n",
    "import building_tokenizer\n",
    "imp.reload(building_tokenizer)\n",
    "import building_tokenizer as toker\n",
    "from functools import reduce\n",
    "\n",
    "buildingName = 'ebu3b'\n",
    "notUcsdBuildings = ['ghc']\n",
    "\n",
    "tokenType = 'NoNumber'\n",
    "if not buildingName in notUcsdBuildings:\n",
    "    naeDict = dict()\n",
    "    naeDict['bonner'] = [\"607\", \"608\", \"609\", \"557\", \"610\"]\n",
    "    naeDict['ap_m'] = ['514', '513','604']\n",
    "    naeDict['bsb'] = ['519', '568', '567', '566', '564', '565']\n",
    "    naeDict['ebu3b'] = [\"505\", \"506\"]\n",
    "    #naeDict['otterson'] = [\"518\", \"517\", \"589\", \"590\"]\n",
    "    naeList = naeDict[buildingName]\n",
    "\n",
    "    labeledFile = 'metadata/' + buildingName + '_sensor_types_location.csv'\n",
    "    with open(labeledFile, 'rb') as fp:\n",
    "        #truthDF = pd.read_excel(fp)\n",
    "        truthDF = pd.DataFrame.from_csv(fp)\n",
    "        #truthDF = truthDF.set_index(keys='Unique Identifier')\n",
    "\n",
    "    wordFeatFile = 'data/wordfeat_'+buildingName+'.pkl'\n",
    "\n",
    "    tokenTypeList = ['NoNumber', 'Alphanumeric', 'AlphaAndNum', 'NumAsSingleWord']\n",
    "\n",
    "    bacnetTypeMapDF = pd.DataFrame.from_csv('metadata/bacnettype_mapping.csv')\n",
    "    unitMap = pd.read_csv('metadata/unit_mapping.csv').set_index('unit')\n",
    "    for val in Counter(unitMap.keys()).values():\n",
    "        if val>1:\n",
    "            \"Unit map file ERROR\"\n",
    "            assert(False)\n",
    "            \n",
    "            \n",
    "    trueDF = pd.DataFrame.from_csv('metadata/'+buildingName+'_sensor_types_location.csv')\n",
    "    sensorDF, nameList, jcinameList, descList, unitList, bacnettypeList, wordList = \\\n",
    "    toker.structure_metadata(buildingName=buildingName, tokenType=tokenType, \\\n",
    "                             validSrcidList=trueDF.index.tolist(), withDotFlag=False)\n",
    "\n",
    "    origSensorDF = deepcopy(sensorDF)\n",
    "    origNameList = deepcopy(nameList)\n",
    "    origJcinameList = deepcopy(jcinameList)\n",
    "    origDescList = deepcopy(descList)\n",
    "    origUnitList = deepcopy(unitList)\n",
    "    origBacnettypeList = deepcopy(bacnettypeList)\n",
    "    origWordList = deepcopy(wordList)\n",
    "\n",
    "    #_, rawNameList, rawJcinameList, rawDescList, _, _, _ = toker.structure_metadata(buildingName=buildingName, tokenType='AlphaAndNum', \\\n",
    "    _, rawNameList, rawJcinameList, rawDescList, _, _, _ =\\\n",
    "    toker.structure_metadata(buildingName=buildingName, tokenType='JustSeparate', \\\n",
    "                             validSrcidList=trueDF.index.tolist(), withDotFlag=False)\n",
    "    \n",
    "    \n",
    "else: \n",
    "    filename = 'metadata/'+buildingName+'_sensor_types_location.csv'\n",
    "    #   filename = 'metadata/%s_sensor_types_location.csv'%buildingName\n",
    "    df = pd.read_csv(filename)\n",
    "    sentenceDict = dict()    \n",
    "    for i,raw in enumerate(df['bas_raw'].tolist()):\n",
    "        sentenceDict[i] = toker.tokenize(tokenType, raw)\n",
    "    \n",
    "    \n",
    "## Common part\n",
    "    \n",
    "#with open('data/'+buildingName+'_str_score_dict.pkl', 'rb') as fp:\n",
    "#    scoreDictDict = pickle.load(fp)\n",
    "#    ### If a word is exactly matched with another, fix it.\n",
    "#    for word, scoreDict in scoreDictDict.items():\n",
    "#        if word in scoreDict.keys():\n",
    "#            scoreDictDict[word] = {word:1}\n",
    "#    scoreDictDict['co'] = {'co2':1}\n",
    "        \n",
    "adder = lambda x,y:x+y\n",
    "splitter = lambda x:x.split()\n",
    "bacnetTypes = list(set(reduce(adder,map(splitter,origBacnettypeList),[])))\n",
    "#for bacnetType in bacnetTypes:\n",
    "#    scoreDictDict[bacnetType] = {bacnetType:1}\n",
    "#units = list(set(unitMap['word'].tolist()))\n",
    "#for unit in units:\n",
    "#    if type(unit)==str:\n",
    "#        scoreDictDict[unit] = {unit:1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"metadata/%s_sentence_dict.json\"%buildingName, \"r\") as fp:\n",
    "    sentenceDict = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "known_label_dict = {\n",
    "    'nae':'network_adapter',\n",
    "    'n': 'network_adapter',\n",
    "    'ebu': 'building',\n",
    "    'b': 'identifier', # b could be basement, which is ignored currently.\n",
    "    'rm':'room',\n",
    "    'vma':'vav',\n",
    "    'newline':'none',\n",
    "    'vnd':'vnd',\n",
    "    'cmd':'command',\n",
    "    'zn':'zone',\n",
    "    'chilled_water_pump': 'chwp',\n",
    "    'clgpid':'cooling_command',\n",
    "    'htgpid':'heating_command',\n",
    "    'rh':'reheat',\n",
    "    'vlv':'valve',\n",
    "    'supflo':'supply_air_flow',\n",
    "    'sup':'supply',\n",
    "    'rf':'return_fan',\n",
    "    'clgmaxflo':'cooling_max_supply_air_flow_setpoint',\n",
    "    'dx':'network_adapter',\n",
    "    'hwp':'hot_water_pump',\n",
    "    'sys':'system',\n",
    "    'dpr':'damper',\n",
    "    'chwp':'chilled_water_pump',\n",
    "    'stpt':'setpoint',\n",
    "    'clgminflo':'cooling_min_supply_air_flow_setpoint',\n",
    "    'clg':'cooling',\n",
    "    'dx':'network_adapter',\n",
    "    'dmpr':'damper',\n",
    "    'pos':'position',\n",
    "    'actclgsp':'effective_cooling_temperature_setpoint',\n",
    "    'clgminflo':'cooling_min_supply_air_flow_setpoint',\n",
    "    'dpr':'damper',\n",
    "    'clgmaxflo':'cooling_max_supply_air_flow_setpoint',\n",
    "    'adj':'adjust',\n",
    "    'commonsp':'temperature_setpoint',\n",
    "    'htgflo':'heating_supply_air_flow_setpoint',\n",
    "    'htg':'heating',\n",
    "    'acthtgsp':'effective_heating_temperature_setpoint',\n",
    "    'sen':'sensor',\n",
    "    'supflosp':'supply_air_flow_setpoint',\n",
    "    'dmprpos':'damper_position',\n",
    "    'htgflow':'heating_supply_air_flow_setpoint',\n",
    "    'sf':'supply_fan',\n",
    "    'chw': 'chilled_water',\n",
    "    'alm':'alarm',\n",
    "    'common':'none',\n",
    "    'ai':'unknown',\n",
    "    'ao':'unknown',\n",
    "    'do':'unknown',\n",
    "    'o': 'none',\n",
    "    'programming': 'nope',\n",
    "    'pid':'none',\n",
    "    'ah':'ahu',\n",
    "    'w':'warm',\n",
    "    'a':'identifier',\n",
    "    'freq':'frequency',\n",
    "    'rate': 'rated'\n",
    "    \n",
    "}\n",
    "known_word_list = known_label_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ask_expert_labels(sentence):\n",
    "    # Input: List of words\n",
    "    # Output: feature list:\n",
    "    # Human operation: Give labels on the words.\n",
    "    sliceSize = 2\n",
    "    featureDict = dict()\n",
    "    \n",
    "    nonBrickTagList = ['none', 'identifier', 'network_adapter', 'vnd', 'unknown']\n",
    "\n",
    "    #for words in rolling_window(sentence, 2):\n",
    "    #    for word in wo\n",
    "    print(\"\\nGiven sentence: %s\"%sentence)\n",
    "    labelList = list()\n",
    "    for word in sentence:\n",
    "        if re.match('[^0-9a-zA-Z]+', word):\n",
    "            labelList.append('none')\n",
    "            continue\n",
    "        if re.match('\\d+', word):\n",
    "            labelList.append('identifier')\n",
    "            continue\n",
    "        if word in known_word_list:\n",
    "            labelList.append(known_label_dict[word])\n",
    "            continue\n",
    "        if word in tagList:\n",
    "            labelList.append(word)\n",
    "            continue\n",
    "            \n",
    "            \n",
    "        while True:\n",
    "            label = input(str(word)+': \\n')\n",
    "            if label in tagList or label in tagsetList or label in nonBrickTagList:\n",
    "                labelList.append(label)\n",
    "                break\n",
    "            else:\n",
    "                print(\"Pick Tag among the following tags: \" + str(tagList))\n",
    "    return labelList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labelFilename = 'metadata/%s_label_dict.json'%buildingName\n",
    "with open(labelFilename, 'r') as fp:\n",
    "    labelListDict = json.load(fp)\n",
    "with open(labelFilename+'.backup', 'w') as fp:\n",
    "    json.dump(labelListDict, fp, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Given sentence: ['nae', '05', 'n', '2', '2', 'vnd', '163', 'shortcyc', 'newline', 'ebu', '3', 'b', '.', 'crac', '-', '2', '.', 'shortcyc', 'newline', 'short', 'cycle', 'newline']\n",
      "shortcyc: \n",
      "none\n",
      "shortcyc: \n",
      "unknown\n",
      "\n",
      "Given sentence: ['nae', '05', 'n', '2', '2', 'vma', '144', 'clgmaxflo', 'newline', 'ebu', '3', 'b', '.', 'rm', '-', '1134', '.', '.', 'clgmaxflo', 'newline', 'cooling', 'max', 'flow', 'newline']\n",
      "\n",
      "Given sentence: ['nae', '06', 'n', '2', '1', 'vma', '148', 't', 'occ', 'newline', 'ebu', '3', 'b', '.', 'rm', '-', '2154', '.', '.', 't', '-', 'occ', 'newline', 'temp', 'occ', 'sts', 'newline']\n",
      "t: \n",
      "temporary\n",
      "occ: \n",
      "occupancy\n",
      "t: \n",
      "temporary\n",
      "occ: \n",
      "occupancy\n",
      "temp: \n",
      "temporary\n",
      "occ: \n",
      "occupancy\n",
      "sts: \n",
      "status\n",
      "\n",
      "Given sentence: ['nae', '05', 'n', '2', '1', 'vma', '103', 'actclgsp', 'newline', 'ebu', '3', 'b', '.', 'rm', '-', 'b', '225', '.', '.', 'actclgsp', 'newline', 'actual', 'cooling', 'setpoint', 'newline']\n",
      "actual: \n",
      "none\n",
      "\n",
      "Given sentence: ['nae', '05', 'n', '2', '2', 'vma', '109', 'w', 'c', 'adj', 'newline', 'ebu', '3', 'b', '.', 'rm', '-', '1213', '.', '.', 'w', '-', 'c', '-', 'adj', 'newline', 'warm', '/', 'cool', 'adjust', 'newline']\n",
      "c: \n",
      "cool\n",
      "c: \n",
      "cool\n",
      "\n",
      "Given sentence: ['nae', '05', 'n', '2', '1', 'vma', '116', 'acthtgsp', 'newline', 'ebu', '3', 'b', '.', 'rm', '-', 'b', '210', '.', '.', 'acthtgsp', 'newline', 'actual', 'heating', 'setpoint', 'newline']\n",
      "actual: \n",
      "effective\n",
      "\n",
      "Given sentence: ['nae', '06', 'n', '2', '1', 'vma', '144', 'clgminflo', 'newline', 'ebu', '3', 'b', '.', 'rm', '-', '2108', '.', '.', 'clgminflo', 'newline', 'occupied', 'clg', 'min', 'newline']\n",
      "\n",
      "Given sentence: ['nae', '05', 'n', '2', '2', 'vma', '150', 'clgmaxflo', 'newline', 'ebu', '3', 'b', '.', 'rm', '-', '1125', '.', '.', 'clgmaxflo', 'newline', 'cooling', 'max', 'flow', 'newline']\n",
      "\n",
      "Given sentence: ['nae', '06', 'hubbs', 'pv', 'current', 'newline', 'hubbs', 'pv', '-', 'current', 'newline', 'pv', 'system', 'output', 'newline']\n",
      "hubbs: \n",
      "building\n",
      "hubbs: \n",
      "building\n",
      "\n",
      "Given sentence: ['nae', '05', 'n', '2', '1', 'nae', '5', 't', '1', 'vnd', '41', 'sf', '1', 'vfd', '41', 'reference', '2', 'newline', 'ebu', '3', 'b', '.', 'sf', '1', '.', 'ref', '-', '2', 'newline', 'reference', '2', 'newline']\n",
      "t: \n",
      "identifier\n",
      "reference: \n",
      "reference\n",
      "Pick Tag among the following tags: ['thermostat', 'powersystem', 'frequency', 'highest', 'underfloor', 'fresh', 'head', 'limit', 'duration', 'fcu', 'occupied', 'ready', 'motion', 'condensor', 'deionised', 'when', 'monthly', 'heater', 'suction', 'emergency', 'schedule', 'water', 'max', 'entering', 'cycle', 'pump', 'fire', 'ahu', 'electrical', 'grains', 'warm', 'duct', 'overridden', 'tolerance', 'dischargefan', 'inverter', 'automatic', 'coldest', 'output', 'steam', 'dhws', 'frost', 'unoccupied', 'change', 'heat', 'medium', 'sash', 'motor', 'basement', 'load', 'freeze', 'deceleration', 'alarm', 'mixed', 'storage', 'perimeter', 'speed', 'yearly', 'vav', 'preheat', 'by', 'safety', 'shutdown', 'peak', 'drive', 'leaving', 'zenith', 'percent', 'voltage', 'undefinedmeasurement', 'protect', 'wind', 'bypass', 'domestic', 'city', 'level', 'pir', 'time', 'flow', 'dead', 'thumbwheel', 'tower', 'running', 'status', 'maintenance', 'humidity', 'lockout', 'velocity', 'solarpanel', 'timer', 'panel', 'failure', 'fans', 'differential', 'integrative', 'exhaustfan', 'pre', 'min', 'pressure', 'condensate', 'di', 'power', 'supply', 'average', 'isolation', 'cutout', 'glycool', 'box', 'thermalenergystorage', 'photovoltaic', 'communication', 'enable', 'request', 'close', 'on', 'decrease', 'exhaust', 'rated', 'proportional', 'zone', 'hail', 'returnfan', 'vent', 'fume', 'sensor', 'emergencygenerator', 'floor', 'capacity', 'lighting', 'push', 'hold', 'solar', 'crac', 'indicator', 'position', 'leak', 'economizer', 'outside', 'shed', 'lightingsystem', 'dualband', 'boiler', 'fan', 'temperature', 'enthalpy', 'pv', 'operating', 'damper', 'standby', 'humidification', 'fumehood', 'integration', 'environment', 'activated', 'space', 'dewpoint', 'generator', 'booster', 'setpoint', 'today', 'open', 'control', 'run', 'ratio', 'disable', 'acceleration', 'humidifier', 'switch', 'azimuth', 'fault', 'econcycle', 'supplyfan', 'meter', 'overload', 'coil', 'system', 'locally', 'factor', 'short', 'heating', 'condenser', 'cooling', 'thermal', 'remotely', 'rain', 'firecontrolpanel', 'hand', 'even', 'stages', 'bus', 'high', 'cool', 'hws', 'chilled', 'code', 'curtailment', 'liquid', 'heatexchanger', 'battery', 'last', 'demandresponse', 'demand', 'room', 'temporary', 'manual', 'terminal', 'hot', 'chiller', 'current', 'tank', 'stack', 'hood', 'trace', 'angle', 'piezoelectric', 'valve', 'energy', 'smoke', 'led', 'dehumidification', 'integral', 'button', 'weather', 'step', 'reset', 'return', 'air', 'stage', 'usage', 'dc', 'exchanger', 'reheat', 'ice', 'detection', 'point', 'no', 'gain', 'watersystem', 'humidify', 'stop', 'lowest', 'hour', 'building', 'band', 'command', 'failed', 'torque', 'increase', 'hvac', 'warmest', 'discharge', 'detected', 'laboratory', 'override', 'gas', 'auto', 'roof', 'freezer', 'luminance', 'co2', 'loss', 'lead', 'server', 'occupancy', 'mode', 'required', 'delay', 'adjust', 'cws', 'wing', 'month', 'dew', 'radiance', 'compressor', 'start', 'low', 'filter', 'vfd', 'lag', 'turn', 'unit', 'off', 'elevator', 'relative', 'static', 'wheel', 'fixed', 'direction', 'cold', 'ventilation', 'response', 'effective', 'conductivity']\n",
      "reference: \n",
      "none\n",
      "ref: \n",
      "none\n",
      "reference: \n",
      "none\n",
      "\n",
      "Given sentence: ['nae', '05', 'n', '2', '2', 'vnd', '162', 'lo', 'humd', 'newline', 'ebu', '3', 'b', '.', 'crac', '-', '1', '.', 'lo', '-', 'humd', 'newline', 'low', 'humidity', 'newline']\n",
      "lo: \n",
      "low\n",
      "humd: \n",
      "humidity\n",
      "lo: \n",
      "low\n",
      "humd: \n",
      "humidity\n",
      "\n",
      "Given sentence: ['nae', '06', 'n', '2', '2', 'vma', '171', 'actclgsp', 'newline', 'ebu', '3', 'b', '.', 'rm', '-', '4102', '.', '.', 'actclgsp', 'newline', 'actual', 'cooling', 'setpoint', 'newline']\n",
      "actual: \n",
      "effective\n",
      "\n",
      "Given sentence: ['nae', '05', 'n', '2', '2', 'vma', '137', 'sup', 'flow', 'newline', 'ebu', '3', 'b', '.', 'rm', '-', '1151', '.', '.', 'sup', '-', 'flow', 'newline', 'actual', 'supply', 'flow', 'newline']\n",
      "actual: \n",
      "none\n",
      "\n",
      "Given sentence: ['nae', '05', 'n', '2', '1', 'vma', '122', 'occ', 'cmd', 'newline', 'ebu', '3', 'b', '.', 'rm', '-', 'b', '270', '.', '.', 'occ', '-', 'cmd', 'newline', 'occupied', 'command', 'newline']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/home/jbkoh/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jbkoh/anaconda3/lib/python3.6/site-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jbkoh/anaconda3/lib/python3.6/site-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    394\u001b[0m         \"\"\"\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv (zmq/backend/cython/socket.c:7683)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv (zmq/backend/cython/socket.c:7460)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy (zmq/backend/cython/socket.c:2344)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/home/jbkoh/anaconda3/lib/python3.6/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc (zmq/backend/cython/socket.c:9621)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-61b3b5cb12a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msrcid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msensorDF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msrcid\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabelListDict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mlabelListDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msrcid\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mask_expert_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentenceDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msrcid\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-0f676ecc980a>\u001b[0m in \u001b[0;36mask_expert_labels\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m': \\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtagList\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtagsetList\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnonBrickTagList\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0mlabelList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jbkoh/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    692\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    695\u001b[0m         )\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jbkoh/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    722\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "labelSampleNum = 50\n",
    "for i in random.sample(range(0,len(sensorDF)), labelSampleNum):\n",
    "    srcid = sensorDF.iloc[i].name\n",
    "    if not srcid in labelListDict.keys():\n",
    "        labelListDict[srcid] = ask_expert_labels(sentenceDict[srcid])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(labelListDict))\n",
    "with open(labelFilename, 'w') as fp:\n",
    "    json.dump(labelListDict,fp, indent=4, separators=(',', ': '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wrongSrcidList = list()\n",
    "for srcid, sentence in sentenceDict.items():\n",
    "    if 't' in sentence and '5' in sentence:\n",
    "        #wrongSrcidList.append(srcid)\n",
    "        if srcid in labelListDict.keys():\n",
    "            print(srcid, sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sensorDF.iloc[0]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
