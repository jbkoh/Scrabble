import json
import pdb
import re

from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import MultiLabelBinarizer
from sklearn.metrics import precision_recall_fscore_support

from scrabble_hierarchy import select_random_samples
import building_tokenizer as toker

def replacer(s):
    if re.findall('\d+', s):
        return ' '
        #return '0'
    elif re.findall('[^0-9a-zA-Z]+', s):
        #return 'specialcharacter'
        return ' '
    else:
        return s.lower()

def joiner(x):
    return ' '.join(x)

def tokenizer(x):
    return x.split()

building= 'ebu3b'

sensorDF, srcid_list, name_list, jciname_list, desc_list, unit_list, bacnettype_list =\
                        toker.parse_sentences(building)
sentence_dict = dict()
for srcid, name, jciname, desc in zip(srcid_list, name_list, jciname_list, desc_list):
    sentence_dict[srcid] = list(map(replacer, name + jciname + desc))

#with open('metadata/{0}_sentence_dict_justseparate.json'.format(building), 'r') as fp:
#    sentence_dict = json.load(fp)
#
#sentence_dict = dict([(srcid, list(map(replacer, sentence))) for srcid, sentence in sentence_dict.items()])
with open('metadata/{0}_ground_truth.json'.format(building), 'r') as fp:
    truth_dict = json.load(fp)

n = 500
learning_srcids = select_random_samples(building, \
                          truth_dict.keys(), \
                          n, \
                          True,\
                          token_type='justseparate',
                          reverse=True,
                          cluster_dict=None)
test_srcids = [srcid for srcid in truth_dict.keys() if srcid not in learning_srcids]

binarizer = MultiLabelBinarizer().fit(truth_dict.values())
vectorizer = TfidfVectorizer(tokenizer=tokenizer).fit(map(joiner, sentence_dict.values()))
learning_doc = [' '.join(sentence_dict[srcid]) for srcid in learning_srcids]
learning_vect_doc = vectorizer.transform(learning_doc)

learning_truth_mat = binarizer.transform([truth_dict[srcid] for srcid in learning_srcids])

classifier = RandomForestClassifier(n_estimators=200, n_jobs=7)
classifier.fit(learning_vect_doc, learning_truth_mat)

test_doc = [' '.join(sentence_dict[srcid]) for srcid in test_srcids]
test_vect_doc = vectorizer.transform(test_doc)

pred_mat = classifier.predict(test_vect_doc)
pred_tagsets = binarizer.inverse_transform(pred_mat)
pred_tagsets_dict = dict([(srcid, pred_tagset) for srcid, pred_tagset in zip(test_srcids, pred_tagsets)])

for srcid in test_srcids:
    if set(pred_tagsets_dict[srcid]) != set(truth_dict[srcid]):
        pdb.set_trace()

test_truth_mat = binarizer.transform([truth_dict[srcid] for srcid in test_srcids])


print(precision_recall_fscore_support(pred_mat, test_truth_mat, average='macro'))
pdb.set_trace()
